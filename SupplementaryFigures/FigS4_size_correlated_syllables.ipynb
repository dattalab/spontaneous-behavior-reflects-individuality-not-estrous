{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c932cb4",
   "metadata": {},
   "source": [
    "imports and data uploads\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9def74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter('ignore')\n",
    "import os\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tools.tools import pinv_extended  \n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38b05632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data\n",
    "cpath = os.getcwd() #assumes mean_df_females is in the same path as the notebook\n",
    "female_mean_df = pd.read_csv(cpath+'/mean_df_female.csv')\n",
    "female_scalar_df = pd.read_csv(cpath+'/scalar_df_female.csv')\n",
    "male_mean_df = pd.read_csv(cpath+'/mean_df_male.csv')\n",
    "male_scalar_df = pd.read_csv(cpath+'/scalar_df_male.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7131dc4",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------- \n",
    "# ANALYSIS\n",
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9229ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_scalars(mean_df,scalar_df,metric='robust'):\n",
    "    # area, height, width, length\n",
    "    if metric=='robust':\n",
    "        hdf = scalar_df.groupby('mouse')['height_ave_mm'].quantile(0.95) - scalar_df.groupby('mouse')['height_ave_mm'].quantile(0.05)\n",
    "        wdf = scalar_df.groupby('mouse')['width_mm'].quantile(0.95) - scalar_df.groupby('mouse')['width_mm'].quantile(0.05)\n",
    "        adf = scalar_df.groupby('mouse')['area_mm'].quantile(0.95) - scalar_df.groupby('mouse')['area_mm'].quantile(0.05)\n",
    "        ldf = scalar_df.groupby('mouse')['length_mm'].quantile(0.95) - scalar_df.groupby('mouse')['length_mm'].quantile(0.05)\n",
    "    \n",
    "    if metric=='range':\n",
    "        hdf = scalar_df.groupby('mouse')['height_ave_mm'].max() - scalar_df.groupby('mouse')['height_ave_mm'].min()\n",
    "        wdf = scalar_df.groupby('mouse')['width_mm'].max() - scalar_df.groupby('mouse')['width_mm'].min()\n",
    "        adf = scalar_df.groupby('mouse')['area_mm'].max() - scalar_df.groupby('mouse')['area_mm'].min()\n",
    "        ldf = scalar_df.groupby('mouse')['length_mm'].max() - scalar_df.groupby('mouse')['length_mm'].min()\n",
    "    \n",
    "    if metric=='max':\n",
    "        hdf = scalar_df.groupby('mouse')['height_ave_mm'].max()\n",
    "        wdf = scalar_df.groupby('mouse')['width_mm'].max()\n",
    "        adf = scalar_df.groupby('mouse')['area_mm'].max()\n",
    "        ldf = scalar_df.groupby('mouse')['length_mm'].max()\n",
    "    \n",
    "    if metric=='min':\n",
    "        hdf = scalar_df.groupby('mouse')['height_ave_mm'].min()\n",
    "        wdf = scalar_df.groupby('mouse')['width_mm'].min()\n",
    "        adf = scalar_df.groupby('mouse')['area_mm'].min()\n",
    "        ldf = scalar_df.groupby('mouse')['length_mm'].min()\n",
    "        \n",
    "    if metric=='mean':\n",
    "        hdf = scalar_df.groupby('mouse')['height_ave_mm'].mean()\n",
    "        wdf = scalar_df.groupby('mouse')['width_mm'].mean()\n",
    "        adf = scalar_df.groupby('mouse')['area_mm'].mean()\n",
    "        ldf = scalar_df.groupby('mouse')['length_mm'].mean()\n",
    "        \n",
    "    #syllable usage\n",
    "    temp_mean_df = mean_df.groupby(by = ['mouse','syllable']).mean()['usage'].reset_index()\n",
    "    mean_df_lc = pd.pivot_table(temp_mean_df, values='usage', index=['mouse'], columns=['syllable']).reset_index().fillna(0)\n",
    "    syll =mean_df_lc.drop(['mouse'], axis=1).to_numpy()\n",
    "    syll = np.vstack(syll)\n",
    "\n",
    "    temp_mean_df['height']=0\n",
    "    temp_mean_df['width']=0\n",
    "    temp_mean_df['area']=0\n",
    "    temp_mean_df['length']=0\n",
    "\n",
    "    mice = sorted(mean_df.mouse.unique())\n",
    "    for i,m in enumerate(mice):\n",
    "        temp_mean_df['height'][temp_mean_df.mouse == m] = hdf.values[i]\n",
    "\n",
    "    for i,m in enumerate(mice):\n",
    "        temp_mean_df['width'][temp_mean_df.mouse == m] = wdf.values[i]\n",
    "\n",
    "    for i,m in enumerate(mice):\n",
    "        temp_mean_df['area'][temp_mean_df.mouse == m] = adf.values[i]\n",
    "\n",
    "    for i,m in enumerate(mice):\n",
    "        temp_mean_df['length'][temp_mean_df.mouse == m] = ldf.values[i]\n",
    "    return temp_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e86f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_scalars = cal_scalars(female_mean_df,female_scalar_df,'robust')\n",
    "male_scalars = cal_scalars(male_mean_df,male_scalar_df,'robust')\n",
    "scalars = ['height','width','area','length']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34194577",
   "metadata": {},
   "source": [
    "# GLM to predict size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "659c8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_syll=[]\n",
    "male_syll=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cc0d3",
   "metadata": {},
   "source": [
    "## for females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e62026c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_data = pd.pivot_table(female_scalars, values='usage', index=['mouse'], columns=['syllable']).reset_index().fillna(0)\n",
    "scalars_data = female_scalars.groupby(['mouse']).mean().drop(['syllable','usage'], axis=1)\n",
    "syll = female_scalars.syllable.unique()\n",
    "\n",
    "#prepare syllable data\n",
    "y = syll_data.drop(['mouse'], axis=1).to_numpy()\n",
    "y_log = np.log(y + 1e-6)\n",
    "x = (y_log - y_log.mean(axis=0, keepdims=True)) / y_log.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8fc857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height model fit  0.9993047495655724\n",
      "width model fit  0.9981311240822363\n",
      "area model fit  0.9999315778204688\n",
      "length model fit  0.9984083395781147\n",
      "size correlated syllables for females:  [ 0 13 19 23 25 27 35 36 46]\n"
     ]
    }
   ],
   "source": [
    "corr_syll=[]\n",
    "for s in scalars:\n",
    "    # run GLM on actual data\n",
    "    y = scalars_data[s].to_numpy().reshape(-1, 1)\n",
    "    lr = ElasticNet(alpha=0.01)\n",
    "    lr.fit(x, y)\n",
    "    print(s,'model fit ',lr.score(x, y))\n",
    "    data_scores = lr.coef_ # score per syllbable\n",
    "    \n",
    "    # shuffle size\n",
    "    it =1000\n",
    "    shuff_scores=[]\n",
    "    for i in range(it):\n",
    "        newy = np.random.permutation(y)\n",
    "        lr.fit(x,newy)\n",
    "        shuff_scores.append(lr.coef_)\n",
    "\n",
    "    threshh = np.quantile(shuff_scores,.975,axis=0) \n",
    "    threshl = np.quantile(shuff_scores,.025,axis=0) \n",
    "    corr_syll.append(syll[(data_scores>threshh) | (data_scores<threshl)]) # add syllables that pass threshold\n",
    "female_syll = np.unique(np.concatenate(corr_syll))\n",
    "print('size correlated syllables for females: ',female_syll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83518e",
   "metadata": {},
   "source": [
    "## for males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9db17697",
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_data = pd.pivot_table(male_scalars, values='usage', index=['mouse'], columns=['syllable']).reset_index().fillna(0)\n",
    "scalars_data = male_scalars.groupby(['mouse']).mean().drop(['syllable','usage'], axis=1)\n",
    "syll = male_scalars.syllable.unique()\n",
    "\n",
    "#prepare syllable data\n",
    "y = syll_data.drop(['mouse'], axis=1).to_numpy()\n",
    "y_log = np.log(y + 1e-6)\n",
    "x = (y_log - y_log.mean(axis=0, keepdims=True)) / y_log.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "653a8b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height model fit  0.9990634758590967\n",
      "width model fit  0.9936843527096059\n",
      "area model fit  0.9998366713614902\n",
      "length model fit  0.9991668705985325\n",
      "size correlated syllables for males:  [ 2  9 15 33 46]\n"
     ]
    }
   ],
   "source": [
    "corr_syll=[]\n",
    "for s in scalars:\n",
    "    # run GLM on actual data\n",
    "    y = scalars_data[s].to_numpy().reshape(-1, 1)\n",
    "    lr = ElasticNet(alpha=0.01)\n",
    "    lr.fit(x, y)\n",
    "    print(s,'model fit ',lr.score(x, y))\n",
    "    data_scores = lr.coef_ # score per syllbable\n",
    "    # shuffle size\n",
    "    it =1000\n",
    "    shuff_scores=[]\n",
    "    for i in range(it):\n",
    "        newy = np.random.permutation(y)\n",
    "        lr.fit(x,newy)\n",
    "        shuff_scores.append(lr.coef_)\n",
    "\n",
    "    threshh = np.quantile(shuff_scores,.975,axis=0) \n",
    "    threshl = np.quantile(shuff_scores,.025,axis=0) \n",
    "    corr_syll.append(syll[(data_scores>threshh) | (data_scores<threshl)]) # add syllables that pass threshold\n",
    "male_syll = np.unique(np.concatenate(corr_syll))\n",
    "print('size correlated syllables for males: ',male_syll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba6a51",
   "metadata": {},
   "source": [
    "## control for co-lineratity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7b229",
   "metadata": {},
   "source": [
    "## for females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b714478",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=female_scalars\n",
    "keep_syll = list(range(50))\n",
    "keep_syll = [ele for ele in keep_syll if ele not in female_syll]\n",
    "data=data[data.syllable.isin(keep_syll)]\n",
    "syll_data = pd.pivot_table(data, values='usage', index=['mouse'], columns=['syllable']).reset_index().fillna(0)\n",
    "scalars_data = data.groupby(['mouse']).mean().drop(['syllable','usage'], axis=1)\n",
    "syll = data.syllable.unique()\n",
    "\n",
    "#prepare syllable data\n",
    "y = syll_data.drop(['mouse'], axis=1).to_numpy()\n",
    "y_log = np.log(y + 1e-6)\n",
    "x = (y_log - y_log.mean(axis=0, keepdims=True)) / y_log.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42ce2e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height model fit  0.9990051391051373\n",
      "width model fit  0.9958390577075106\n",
      "area model fit  0.9997705135707747\n",
      "length model fit  0.9980309873978669\n",
      "additional size correlated syllables for females:  [ 2 10 16 38 40 47]\n"
     ]
    }
   ],
   "source": [
    "corr_syll=[]\n",
    "for s in scalars:\n",
    "    # run GLM on actual data\n",
    "    y = scalars_data[s].to_numpy().reshape(-1, 1)\n",
    "    lr = ElasticNet(alpha=0.01)\n",
    "    lr.fit(x, y)\n",
    "    print(s,'model fit ',lr.score(x, y))\n",
    "    data_scores = lr.coef_ # score per syllbable    \n",
    "    # shuffle size\n",
    "    it =1000\n",
    "    shuff_scores=[]\n",
    "    for i in range(it):\n",
    "        newy = np.random.permutation(y)\n",
    "        lr.fit(x,newy)\n",
    "        shuff_scores.append(lr.coef_)\n",
    "\n",
    "    threshh = np.quantile(shuff_scores,.975,axis=0) \n",
    "    threshl = np.quantile(shuff_scores,.025,axis=0) \n",
    "    corr_syll.append(syll[(data_scores>threshh) | (data_scores<threshl)]) # add syllables that pass threshold\n",
    "female_syll2 = np.unique(np.concatenate(corr_syll))\n",
    "print('additional size correlated syllables for females: ',female_syll2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8b3b4",
   "metadata": {},
   "source": [
    "## for males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0ee48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=male_scalars\n",
    "keep_syll = list(range(50))\n",
    "keep_syll = [ele for ele in keep_syll if ele not in male_syll]\n",
    "data=data[data.syllable.isin(keep_syll)]\n",
    "syll_data = pd.pivot_table(data, values='usage', index=['mouse'], columns=['syllable']).reset_index().fillna(0)\n",
    "scalars_data = data.groupby(['mouse']).mean().drop(['syllable','usage'], axis=1)\n",
    "syll = data.syllable.unique()\n",
    "\n",
    "#prepare syllable data\n",
    "y = syll_data.drop(['mouse'], axis=1).to_numpy()\n",
    "y_log = np.log(y + 1e-6)\n",
    "x = (y_log - y_log.mean(axis=0, keepdims=True)) / y_log.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c17d75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height model fit  0.999224867877009\n",
      "width model fit  0.9910989131486606\n",
      "area model fit  0.9997241295362839\n",
      "length model fit  0.9991516873309965\n",
      "additional size correlated syllables for males:  [18 27 39]\n"
     ]
    }
   ],
   "source": [
    "corr_syll=[]\n",
    "for s in scalars:\n",
    "    # run GLM on actual data\n",
    "    y = scalars_data[s].to_numpy().reshape(-1, 1)\n",
    "    lr = ElasticNet(alpha=0.01)\n",
    "    lr.fit(x, y)\n",
    "    print(s,'model fit ',lr.score(x, y))\n",
    "    data_scores = lr.coef_ # score per syllbable\n",
    "  \n",
    "    # shuffle size\n",
    "    it =1000\n",
    "    shuff_scores=[]\n",
    "    for i in range(it):\n",
    "        newy = np.random.permutation(y)\n",
    "        lr.fit(x,newy)\n",
    "        shuff_scores.append(lr.coef_)\n",
    "\n",
    "    threshh = np.quantile(shuff_scores,.975,axis=0) \n",
    "    threshl = np.quantile(shuff_scores,.025,axis=0) \n",
    "    corr_syll.append(syll[(data_scores>threshh) | (data_scores<threshl)]) # add syllables that pass threshold\n",
    "male_syll2 = np.unique(np.concatenate(corr_syll))\n",
    "print('additional size correlated syllables for males: ',male_syll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92026b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## syllables\n",
    "male_syll=np.concatenate([male_syll,male_syll2])\n",
    "female_syll=np.concatenate([female_syll,female_syll2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "127cffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size correlated syllables for males:  [2, 9, 15, 18, 27, 33, 39, 46]\n",
      "size correlated syllables for females:  [0, 2, 10, 13, 16, 19, 23, 25, 27, 35, 36, 38, 40, 46, 47]\n"
     ]
    }
   ],
   "source": [
    "print('size correlated syllables for males: ',sorted(male_syll))\n",
    "print('size correlated syllables for females: ',sorted(female_syll))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
